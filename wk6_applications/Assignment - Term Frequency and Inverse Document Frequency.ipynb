{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment TF-IDF\n",
    "Compute Term Frequency and Inverse Document Frequency using the wikipedia dataset. Find the result of TFxITF of term ('labor', 12)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse data and create RDD for terms - (word, article_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "import re\n",
    "\n",
    "sc = SparkContext()\n",
    "\n",
    "def parse_article(line):\n",
    "    try:\n",
    "        article_id, text = unicode(line.rstrip()).split('\\t', 1)\n",
    "        text = re.sub(\"^\\W+|\\W+$\", \"\", text, flags=re.UNICODE)\n",
    "        words = re.split(\"\\W*\\s+\\W*\", text, flags=re.UNICODE)\n",
    "        return [(word.lower(), int(article_id)) for word in words]\n",
    "    except ValueError as e:\n",
    "        return []\n",
    "\n",
    "raw_data = sc.textFile(\"/data/wiki/en_articles_part/articles-part\", 16).flatMap(parse_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'anarchism', 12), (u'anarchism', 12), (u'is', 12)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load StopWords to filter RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\r\n",
      "about\r\n",
      "above\r\n",
      "across\r\n",
      "after\r\n",
      "afterwards\r\n",
      "again\r\n",
      "against\r\n",
      "all\r\n",
      "almost\r\n"
     ]
    }
   ],
   "source": [
    "! head /datasets/stop_words_en.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4.0K\r\n",
      "-rw-rw-r-- 1 jovyan root 1.9K Sep 11  2017 stop_words_en.txt\r\n"
     ]
    }
   ],
   "source": [
    "! ls -lh /datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load stopwords dictionary - file is small enough \n",
    "stopWords_data = sc.textFile('/datasets/stop_words_en.txt').collect()\n",
    "stopWords_broadcast = sc.broadcast(stopWords_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = raw_data.filter(lambda term: term[0] not in stopWords_broadcast.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'anarchism', 12), (u'anarchism', 12), (u'defined', 12)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDD: Term Counts  - ((word, article_id), count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_counts = terms.map(lambda term: (term, 1)).reduceByKey(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((u'lifelong', 9002), 1),\n",
       " ((u'fulfill', 2085), 1),\n",
       " ((u'appalachiosaurus', 1367), 1)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms_counts.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[149]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms_counts.lookup((u'anarchism', 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDD: total number of words in each article - (article_id, no_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_words_counts = terms.map(lambda term: (term[1], 1)).reduceByKey(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1536, 224), (2560, 1422), (5808, 3020)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_words_counts.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6096]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_words_counts.lookup(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dt - number of documents in the dataset with particular term - (word, no_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dt = terms.distinct().countByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dt[u'anarchism']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDD: TF&IDF - (term, TF * IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# be careful! nested RDD operation is not allowed in spark !!!\n",
    "# solution 1: broadcast article_words_counts into memory if possible\n",
    "# solution 2: join two RDDs into one\n",
    "\n",
    "\n",
    "# solution 1\n",
    "\n",
    "article_words_counts_broadcast = sc.broadcast({term[0]: term[1] for term in article_words_counts.collect()})\n",
    "\n",
    "def compute(term_count):\n",
    "    (word, article_id), count = term_count\n",
    "    # compute tf, tf(word, article_id) = N_word / N\n",
    "    TF = float(count) / article_words_counts_broadcast.value[article_id]\n",
    "    # compute idf, idf(word, article_id) = 1 / log(1 + Dt)\n",
    "    IDF = 1.0 / math.log(1 + Dt[word])\n",
    "#     return (word, IDF)\n",
    "    return ((word, article_id), TF * IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_tf_idf = terms_counts.map(compute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.00035046896210986204]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms_tf_idf.lookup((u'labor', 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
